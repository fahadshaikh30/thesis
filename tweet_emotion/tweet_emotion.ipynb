{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class for data preparation\n",
    "class SimpleDataset:\n",
    "    def __init__(self, tokenized_texts):\n",
    "        self.tokenized_texts = tokenized_texts\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_texts[\"input_ids\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.tokenized_texts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6530cb5970b47e4b1970bdc7436cb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/294 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e5c676a312483898ebe9384903f682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/0.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aedd314f5404348962981013ea49d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/780k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b659679bd1f1403d836da07717e65ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371177cc4ad6494aa43d2c58e61a103d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2194f5706b2141ec9b2f9084ba55dd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f771f361804461863359b01afe160e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/313M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load tokenizer and model, create trainer\n",
    "model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "trainer = Trainer(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\fashaikh\\Desktop\\Thesis main\\partitioned_data\\LDSEnclaves.parquet'\n",
    "df = pd.read_parquet(path)\n",
    "\n",
    "text = list(df['cleanedContent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize texts and create prediction data set\n",
    "tokenized_texts = tokenizer(text,truncation=True,padding=True)\n",
    "pred_dataset = SimpleDataset(tokenized_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 6831\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f41d97662944da59085764961e88aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run predictions\n",
    "predictions = trainer.predict(pred_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform predictions to labels\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "labels = pd.Series(preds).map(model.config.id2label)\n",
    "scores = (np.exp(predictions[0])/np.exp(predictions[0]).sum(-1,keepdims=True)).max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores raw\n",
    "temp = (np.exp(predictions[0])/np.exp(predictions[0]).sum(-1,keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work in progress\n",
    "# container\n",
    "anger = []\n",
    "disgust = []\n",
    "fear = []\n",
    "joy = []\n",
    "neutral = []\n",
    "sadness = []\n",
    "surprise = []\n",
    "\n",
    "# extract scores (as many entries as exist in pred_texts)\n",
    "for i in range(len(text)):\n",
    "  anger.append(temp[i][0])\n",
    "  disgust.append(temp[i][1])\n",
    "  fear.append(temp[i][2])\n",
    "  joy.append(temp[i][3])\n",
    "  neutral.append(temp[i][4])\n",
    "  sadness.append(temp[i][5])\n",
    "  surprise.append(temp[i][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user WY isn't WY without wild horses. Stop BL...</td>\n",
       "      <td>2</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.776890</td>\n",
       "      <td>0.169959</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.776890</td>\n",
       "      <td>0.007091</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.035180</td>\n",
       "      <td>0.006101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user BLM must abandon plan to eradicate 40% o...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.428445</td>\n",
       "      <td>0.428445</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.420934</td>\n",
       "      <td>0.029228</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.102040</td>\n",
       "      <td>0.007966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user @user @user @user - as your consti...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.118623</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>0.027564</td>\n",
       "      <td>0.003012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@user BLM must abandon plan to eradicate 40% o...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.428445</td>\n",
       "      <td>0.428445</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.420934</td>\n",
       "      <td>0.029228</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.102040</td>\n",
       "      <td>0.007966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user BLM must abandon plan to eradicate 40% o...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.428445</td>\n",
       "      <td>0.428445</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.420934</td>\n",
       "      <td>0.029228</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.102040</td>\n",
       "      <td>0.007966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  pred  label     score   \n",
       "0  @user WY isn't WY without wild horses. Stop BL...     2   fear  0.776890  \\\n",
       "1  @user BLM must abandon plan to eradicate 40% o...     0  anger  0.428445   \n",
       "2  @user @user @user @user @user - as your consti...     0  anger  0.835694   \n",
       "3  @user BLM must abandon plan to eradicate 40% o...     0  anger  0.428445   \n",
       "4  @user BLM must abandon plan to eradicate 40% o...     0  anger  0.428445   \n",
       "\n",
       "      anger   disgust      fear       joy   neutral   sadness  surprise  \n",
       "0  0.169959  0.000374  0.776890  0.007091  0.004405  0.035180  0.006101  \n",
       "1  0.428445  0.001105  0.420934  0.029228  0.010283  0.102040  0.007966  \n",
       "2  0.835694  0.000482  0.118623  0.011356  0.003269  0.027564  0.003012  \n",
       "3  0.428445  0.001105  0.420934  0.029228  0.010283  0.102040  0.007966  \n",
       "4  0.428445  0.001105  0.420934  0.029228  0.010283  0.102040  0.007966  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with texts, predictions, labels, and scores\n",
    "df = pd.DataFrame(list(zip(text,preds,labels,scores,  anger, disgust, fear, joy, neutral, sadness, surprise)), columns=['text','pred','label','score', 'anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "anger       2819\n",
       "fear        1736\n",
       "neutral     1046\n",
       "surprise     481\n",
       "sadness      365\n",
       "joy          320\n",
       "disgust       64\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweetnlp\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/config.json not found in cache or force_download set to True, downloading to C:\\Users\\fashaikh\\.cache\\huggingface\\transformers\\tmp4yv07br6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4702e4a7e26342539f85d02139b38a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/config.json in cache at C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\a093d176a154ca924192427bcbca1a8c313d9519aa9d4bb0d346fc6563649fbc.e4359fd65495b9b21f6e032c53184cb71b81a0ba2ef982df8959daa4fa0e293a\n",
      "creating metadata file for C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\a093d176a154ca924192427bcbca1a8c313d9519aa9d4bb0d346fc6563649fbc.e4359fd65495b9b21f6e032c53184cb71b81a0ba2ef982df8959daa4fa0e293a\n",
      "loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/config.json from cache at C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\a093d176a154ca924192427bcbca1a8c313d9519aa9d4bb0d346fc6563649fbc.e4359fd65495b9b21f6e032c53184cb71b81a0ba2ef982df8959daa4fa0e293a\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"anger\",\n",
      "    \"1\": \"anticipation\",\n",
      "    \"2\": \"disgust\",\n",
      "    \"3\": \"fear\",\n",
      "    \"4\": \"joy\",\n",
      "    \"5\": \"love\",\n",
      "    \"6\": \"optimism\",\n",
      "    \"7\": \"pessimism\",\n",
      "    \"8\": \"sadness\",\n",
      "    \"9\": \"surprise\",\n",
      "    \"10\": \"trust\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 0,\n",
      "    \"anticipation\": 1,\n",
      "    \"disgust\": 2,\n",
      "    \"fear\": 3,\n",
      "    \"joy\": 4,\n",
      "    \"love\": 5,\n",
      "    \"optimism\": 6,\n",
      "    \"pessimism\": 7,\n",
      "    \"sadness\": 8,\n",
      "    \"surprise\": 9,\n",
      "    \"trust\": 10\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to C:\\Users\\fashaikh\\.cache\\huggingface\\transformers\\tmpy2n8dzf0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19b3ef0bf12443684776e931573386b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/409 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/tokenizer_config.json in cache at C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\e85e9ebc19ce8eef43c1d35ac19e42260dd63737a9e1d3b6d399b301729d4fee.e5993163038bca1cc1c23c854d00149bd80b4fde64fb7f906313dad0886c5783\n",
      "creating metadata file for C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\e85e9ebc19ce8eef43c1d35ac19e42260dd63737a9e1d3b6d399b301729d4fee.e5993163038bca1cc1c23c854d00149bd80b4fde64fb7f906313dad0886c5783\n",
      "https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/vocab.json not found in cache or force_download set to True, downloading to C:\\Users\\fashaikh\\.cache\\huggingface\\transformers\\tmpcpdmxn9g\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e241aa0cbfa4a44b9c8ec7405c43315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/780k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/vocab.json in cache at C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\5711ed52026b6c6a3990b6b9b61ad36d14d88b69262bbc191a6d13938c592223.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "creating metadata file for C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\5711ed52026b6c6a3990b6b9b61ad36d14d88b69262bbc191a6d13938c592223.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/merges.txt not found in cache or force_download set to True, downloading to C:\\Users\\fashaikh\\.cache\\huggingface\\transformers\\tmppmi57zph\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d813ca0e9ee4c6bac4cbbba89e60e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/merges.txt in cache at C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\a43a5e7fedcd400e0e49e11de9ea1f02114d536afd61f7834d7ec8df68d91ff1.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "creating metadata file for C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\a43a5e7fedcd400e0e49e11de9ea1f02114d536afd61f7834d7ec8df68d91ff1.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to C:\\Users\\fashaikh\\.cache\\huggingface\\transformers\\tmp51bgv8ut\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2530642f83414804a83bf9f044ed8b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.01M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/tokenizer.json in cache at C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\d5196c83ae47649f98f810f831dc984aafa2d16847f7809f1ef929abd857b13c.1d5d530b5229dbca3dfd2235e27250542ef41720aa101041bc4c7a01ea22b470\n",
      "creating metadata file for C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\d5196c83ae47649f98f810f831dc984aafa2d16847f7809f1ef929abd857b13c.1d5d530b5229dbca3dfd2235e27250542ef41720aa101041bc4c7a01ea22b470\n",
      "https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to C:\\Users\\fashaikh\\.cache\\huggingface\\transformers\\tmpady_2af8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f8bc7fa7814d70bed2a073e1708662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/special_tokens_map.json in cache at C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\653dd6788645906ff4b76f83858a49606b2505243ade87c2aa2aa00a83b5a77a.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "creating metadata file for C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\653dd6788645906ff4b76f83858a49606b2505243ade87c2aa2aa00a83b5a77a.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/vocab.json from cache at C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\5711ed52026b6c6a3990b6b9b61ad36d14d88b69262bbc191a6d13938c592223.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/merges.txt from cache at C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\a43a5e7fedcd400e0e49e11de9ea1f02114d536afd61f7834d7ec8df68d91ff1.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/tokenizer.json from cache at C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\d5196c83ae47649f98f810f831dc984aafa2d16847f7809f1ef929abd857b13c.1d5d530b5229dbca3dfd2235e27250542ef41720aa101041bc4c7a01ea22b470\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/special_tokens_map.json from cache at C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\653dd6788645906ff4b76f83858a49606b2505243ade87c2aa2aa00a83b5a77a.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/tokenizer_config.json from cache at C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\e85e9ebc19ce8eef43c1d35ac19e42260dd63737a9e1d3b6d399b301729d4fee.e5993163038bca1cc1c23c854d00149bd80b4fde64fb7f906313dad0886c5783\n",
      "https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to C:\\Users\\fashaikh\\.cache\\huggingface\\transformers\\tmplc3u5qi5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289e5eea4b854fd1bcc10dee2c06072e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/476M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/pytorch_model.bin in cache at C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\38eb574d544ae6dd9583d92cb7b7fb8404faf4e83794c63937e1ffaf80a73a5b.fa8aafca908cdf08d8a16aab630fb2e521c1bfe7305d198cccf065e0c86011e8\n",
      "creating metadata file for C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\38eb574d544ae6dd9583d92cb7b7fb8404faf4e83794c63937e1ffaf80a73a5b.fa8aafca908cdf08d8a16aab630fb2e521c1bfe7305d198cccf065e0c86011e8\n",
      "loading weights file https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion-multilabel-latest/resolve/main/pytorch_model.bin from cache at C:\\Users\\fashaikh/.cache\\huggingface\\transformers\\38eb574d544ae6dd9583d92cb7b7fb8404faf4e83794c63937e1ffaf80a73a5b.fa8aafca908cdf08d8a16aab630fb2e521c1bfe7305d198cccf065e0c86011e8\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion-multilabel-latest.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# MULTI-LABEL MODEL \n",
    "model = tweetnlp.load_model('emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\fashaikh\\Desktop\\Thesis main\\partitioned_data\\LDSEnclaves.parquet'\n",
    "df2 = pd.read_parquet(path)\n",
    "\n",
    "text = list(df2['cleanedContent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for i in text:\n",
    "    sentiment_result = model.emotion(i, return_probability=True)\n",
    "    res.append(sentiment_result)\n",
    "    \n",
    "data = pd.json_normalize(res)\n",
    "\n",
    "df3 = pd.concat(objs=[df2, data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "anger           3251\n",
       "anticipation    1363\n",
       "joy              667\n",
       "disgust          520\n",
       "optimism         512\n",
       "fear             390\n",
       "sadness          125\n",
       "surprise           3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
